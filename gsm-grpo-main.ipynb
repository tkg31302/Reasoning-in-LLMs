{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Installation","metadata":{}},{"cell_type":"code","source":" %%capture\n!pip install unsloth vllm\n!pip install triton==3.1.0\n!pip install -U pynvml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:36:22.145342Z","iopub.execute_input":"2025-03-08T07:36:22.145636Z","iopub.status.idle":"2025-03-08T07:37:34.837976Z","shell.execute_reply.started":"2025-03-08T07:36:22.145606Z","shell.execute_reply":"2025-03-08T07:37:34.836794Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### Unsloth","metadata":{}},{"cell_type":"code","source":"hp_model_name = \"unsloth/Phi-4\"\nhp_dataset = 'gsm'\nhp_max_steps = 200\nhp_run_name = f\"{hp_model_name.split('/')[1]}-{hp_dataset}-{hp_max_steps}-steps\"\n\n\nhp_lora_rank = 16\nhp_max_comp_len = 200\nhp_max_seq_len = 1024","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:37:34.838951Z","iopub.execute_input":"2025-03-08T07:37:34.839222Z","iopub.status.idle":"2025-03-08T07:37:34.843380Z","shell.execute_reply.started":"2025-03-08T07:37:34.839197Z","shell.execute_reply":"2025-03-08T07:37:34.842547Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from unsloth import FastLanguageModel, PatchFastRL\nPatchFastRL(\"GRPO\", FastLanguageModel)","metadata":{"id":"59DIs5BMcvjN","outputId":"a4b3de70-c99c-4e76-ee06-dab6a6505a8b","trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:37:34.844096Z","iopub.execute_input":"2025-03-08T07:37:34.844325Z","iopub.status.idle":"2025-03-08T07:38:06.228684Z","shell.execute_reply.started":"2025-03-08T07:37:34.844301Z","shell.execute_reply":"2025-03-08T07:38:06.228028Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Patching Xformers to fix some performance issues.\nðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\nðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from unsloth import is_bfloat16_supported\nimport torch\nmax_seq_length = hp_max_seq_len # Can increase for longer reasoning traces\nlora_rank = hp_lora_rank # Larger rank = smarter, but slower\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = hp_model_name,\n    max_seq_length = max_seq_length,\n    load_in_4bit = True, # False for LoRA 16bit\n    fast_inference = True, # Enable vLLM fast inference\n    max_lora_rank = lora_rank,\n    gpu_memory_utilization = 0.7, # Reduce if out of memory\n)\n\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\n        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n        \"gate_proj\", \"up_proj\", \"down_proj\",\n    ], # Remove QKVO if out of memory\n    lora_alpha = lora_rank,\n    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n    random_state = 3407,\n)","metadata":{"id":"DkIvEkIIkEyB","outputId":"514dea04-804e-47a8-b891-ed3f4a6fb530","trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:38:06.229512Z","iopub.execute_input":"2025-03-08T07:38:06.229813Z","iopub.status.idle":"2025-03-08T07:40:20.862009Z","shell.execute_reply.started":"2025-03-08T07:38:06.229781Z","shell.execute_reply":"2025-03-08T07:40:20.861352Z"}},"outputs":[{"name":"stdout","text":"INFO 03-08 07:38:07 __init__.py:207] Automatically detected platform cuda.\nUnsloth: Switching from Unsloth dynamic quant to normal quant since\nwe do not yet support fast inference for unsloth/phi-4-unsloth-bnb-4bit\n==((====))==  Unsloth 2025.3.8: Fast Llama patching. Transformers: 4.49.0. vLLM: 0.7.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93cbfcbbc8d24d68ade47e0f9b0c065c"}},"metadata":{}},{"name":"stdout","text":"Unsloth: Your GPU cannot handle sequence lengths of 1024 due to limited GPU memory.\nUnsloth: Your GPU can only handle approximately the maximum sequence length of 1024.\nUnsloth: vLLM loading unsloth/phi-4-bnb-4bit with actual GPU utilization = 69.34%\nUnsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.74 GB.\nUnsloth: Using conservativeness = 1.0. Chunked prefill tokens = 1024. Num Sequences = 128.\nUnsloth: vLLM's KV Cache can use up to 0.25 GB. Also swap space = 5 GB.\nWARNING 03-08 07:38:10 config.py:2448] Casting torch.bfloat16 to torch.float16.\nINFO 03-08 07:38:22 config.py:549] This model supports multiple tasks: {'generate', 'embed', 'score', 'reward', 'classify'}. Defaulting to 'generate'.\nUnsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection'], 'llm_int8_threshold': 6.0}\nINFO 03-08 07:38:22 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='unsloth/phi-4-bnb-4bit', speculative_config=None, tokenizer='unsloth/phi-4-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=1024, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/phi-4-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":128}, use_cached_outputs=False, \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/18.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d12bc06948d4eab9a5cc881bca59b4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.61M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c0a187829614ba1af093eb16d1748c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/917k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab91fce53551453097341628aedcd837"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.15M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3be66101699b459ea1d5f2fc1a433cbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"699a2dd179c24374accc7c84140b0788"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/170 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54394918070b47fe93f4afdebc6e3622"}},"metadata":{}},{"name":"stdout","text":"INFO 03-08 07:38:25 cuda.py:178] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\nINFO 03-08 07:38:25 cuda.py:226] Using XFormers backend.\nINFO 03-08 07:38:36 model_runner.py:1110] Starting to load model unsloth/phi-4-bnb-4bit...\nINFO 03-08 07:38:36 loader.py:1089] Loading weights with BitsAndBytes quantization.  May take a while ...\nINFO 03-08 07:38:36 weight_utils.py:254] Using model weights format ['*.safetensors']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ec60277d27e4bc7b56f8f0232425762"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"110d86c68dc245fb8e8c93ccdeda918a"}},"metadata":{}},{"name":"stdout","text":"INFO 03-08 07:38:59 weight_utils.py:270] Time spent downloading weights for unsloth/phi-4-bnb-4bit: 23.213420 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"514840afc4c94c79b191cd3663e61326"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83b463689e304dbda35d403b435c93f5"}},"metadata":{}},{"name":"stdout","text":"INFO 03-08 07:39:08 model_runner.py:1115] Loading model weights took 8.4920 GB\nINFO 03-08 07:39:08 logger.py:57] Using PunicaWrapperGPU.\nINFO 03-08 07:39:23 worker.py:267] Memory profiling takes 14.60 seconds\nINFO 03-08 07:39:23 worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.69) = 10.22GiB\nINFO 03-08 07:39:23 worker.py:267] model weights take 8.49GiB; non_torch_memory takes 0.03GiB; PyTorch activation peak memory takes 0.47GiB; the rest of the memory reserved for KV Cache is 1.23GiB.\nINFO 03-08 07:39:23 executor_base.py:111] # cuda blocks: 402, # CPU blocks: 1638\nINFO 03-08 07:39:23 executor_base.py:116] Maximum concurrency for 1024 tokens per request: 6.28x\nINFO 03-08 07:39:27 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n","output_type":"stream"},{"name":"stderr","text":"Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:38<00:00,  2.02s/it]","output_type":"stream"},{"name":"stdout","text":"INFO 03-08 07:40:06 model_runner.py:1562] Graph capturing finished in 38 secs, took 0.65 GiB\nINFO 03-08 07:40:06 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 57.98 seconds\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/18.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6847b0ad18ab44649b79f3525b44899c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.61M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38c6d53ee4134ac080f29fc9f91ee773"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/917k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8a47d9de6f8441593d2d1ec0663a4ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02ab7695417341ccb86588e4fc00d4e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.15M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7e8653151a04bd4a05eda09cef0613e"}},"metadata":{}},{"name":"stderr","text":"Unsloth 2025.3.8 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Data Prep\n<a name=\"Data\"></a>","metadata":{"id":"7KGgPgk_5S8r"}},{"cell_type":"code","source":"import re\nfrom datasets import load_dataset, Dataset\n\n# Load and prep dataset\nSYSTEM_PROMPT = \"\"\"\nRespond in the following format:\n<reasoning>\n...\n</reasoning>\n<answer>\n...\n</answer>\n\"\"\"\n\nXML_COT_FORMAT = \"\"\"\\\n<reasoning>\n{reasoning}\n</reasoning>\n<answer>\n{answer}\n</answer>\n\"\"\"\n\ndef extract_xml_answer(text: str) -> str:\n    answer = text.split(\"<answer>\")[-1]\n    answer = answer.split(\"</answer>\")[0]\n    return answer.strip()\n\ndef extract_hash_answer(text: str) -> str | None:\n    if \"####\" not in text:\n        return None\n    return text.split(\"####\")[1].strip()\n\n# uncomment middle messages for 1-shot prompting\ndef get_gsm8k_questions(split=\"train\") -> Dataset:\n    data = load_dataset('openai/gsm8k', 'main')[split]  # type: ignore\n    data = data.map(lambda x: {  # type: ignore\n        'prompt': tokenizer.apply_chat_template([\n            {'role': 'system', 'content': SYSTEM_PROMPT},\n            {'role': 'user', 'content': x['question']}\n        ], tokenize=False, continue_final_message=True),\n        'question': x['question'],\n        'answer': extract_hash_answer(x['answer'])\n    })  # type: ignore\n    return data  # type: ignore\n    \ndataset = get_gsm8k_questions()\n\n# Reward functions\ndef correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n    # responses = [completion[0]['content'] for completion in completions]\n    # q = prompts[0][-1]['content']\n    extracted_responses = [extract_xml_answer(r) for r in completions]\n    # print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n\ndef int_reward_func(completions, **kwargs) -> list[float]:\n    extracted_responses = [extract_xml_answer(r) for r in completions]\n    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n\ndef strict_format_reward_func(completions, **kwargs) -> list[float]:\n    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n    matches = [re.match(pattern, r) for r in completions]\n    return [0.5 if match else 0.0 for match in matches]\n\ndef soft_format_reward_func(completions, **kwargs) -> list[float]:\n    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n    matches = [re.match(pattern, r) for r in completions]\n    return [0.5 if match else 0.0 for match in matches]\n\ndef count_xml(text) -> float:\n    count = 0.0\n    if text.count(\"<reasoning>\\n\") == 1:\n        count += 0.125\n    if text.count(\"\\n</reasoning>\\n\") == 1:\n        count += 0.125\n    if text.count(\"\\n<answer>\\n\") == 1:\n        count += 0.125\n        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n    if text.count(\"\\n</answer>\") == 1:\n        count += 0.125\n        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n    return count\n\ndef xmlcount_reward_func(completions, **kwargs) -> list[float]:\n    return [count_xml(c) for c in completions]","metadata":{"id":"cXk993X6C2ZZ","trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:40:20.862989Z","iopub.execute_input":"2025-03-08T07:40:20.863356Z","iopub.status.idle":"2025-03-08T07:40:24.403974Z","shell.execute_reply.started":"2025-03-08T07:40:20.863322Z","shell.execute_reply":"2025-03-08T07:40:24.403240Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"267c5ed0fd4d48ac90d6bf474e6e563d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abf059b269f146ebaa513731ac5ae720"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eda9587536b44935bea9618217d32b50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90d0c9c481d643b98d132044a79f5ff9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec0b5a5eadec4dc5882cd541e1823480"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7473 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f265e2d17e047ccaaea2031c52d8464"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"I = 1\ndef write_model_outputs_to_file(prompts, completions, answer, output_dir=\"model_outputs_text\", **kwargs):\n    global I\n    try:\n        os.makedirs(output_dir, exist_ok=True)\n        filename = os.path.join(output_dir, f\"output_{I}.txt\")\n\n        with open(filename, \"w\", encoding=\"utf-8\") as file:\n            for i, (p, c, a) in enumerate(zip(prompts, completions, answer), 1):\n                file.write(f\"Example {i}:\\n\")\n                file.write(\"Prompt:\\n\")\n                file.write(str(p).strip() + \"\\n\")\n                file.write(\"-\" * 30 + \"\\n\")\n                file.write(\"Model Completion:\\n\")\n                file.write(str(c).strip() + \"\\n\")\n                file.write(\"-\" * 30 + \"\\n\")\n                file.write(\"Expected Answer:\\n\")\n                file.write(str(a).strip() + \"\\n\")\n                file.write(\"=\" * 50 + \"\\n\\n\")\n        I += 1\n\n    except Exception as e:\n        print(f\"Error writing to file: {e}\")\n        return None\n\n    return 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:40:24.406138Z","iopub.execute_input":"2025-03-08T07:40:24.406393Z","iopub.status.idle":"2025-03-08T07:40:24.412572Z","shell.execute_reply.started":"2025-03-08T07:40:24.406372Z","shell.execute_reply":"2025-03-08T07:40:24.411690Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"<a name=\"Train\"></a>\n### Train the model","metadata":{"id":"Ux6iqP7z5YOo"}},{"cell_type":"code","source":"import wandb\nimport os\n\nwandb.login(key='86ba02d4ce42eb3527e4f33a4bd8e46b4bcbfce2')\nos.environ[\"WANDB_PROJECT\"] = \"dsc_250_train\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:40:24.413741Z","iopub.execute_input":"2025-03-08T07:40:24.413969Z","iopub.status.idle":"2025-03-08T07:40:31.309266Z","shell.execute_reply.started":"2025-03-08T07:40:24.413949Z","shell.execute_reply":"2025-03-08T07:40:31.308627Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikhil-23\u001b[0m (\u001b[33mteam-nik\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from trl import GRPOConfig, GRPOTrainer\ntraining_args = GRPOConfig(\n    use_vllm = True, # use vLLM for fast inference!\n    learning_rate = 5e-6,\n    adam_beta1 = 0.9,\n    adam_beta2 = 0.99,\n    weight_decay = 0.1,\n    warmup_ratio = 0.1,\n    lr_scheduler_type = \"cosine\",\n    optim = \"paged_adamw_8bit\",\n    logging_steps = 1,\n    bf16 = is_bfloat16_supported(),\n    fp16 = not is_bfloat16_supported(),\n    per_device_train_batch_size = 1,\n    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n    num_generations = 6, # Decrease if out of memory\n    max_prompt_length = 256,\n    max_completion_length = hp_max_comp_len,\n    # num_train_epochs = 1, # Set to 1 for a full training run\n    max_steps = hp_max_steps,\n    save_steps = 250,\n    max_grad_norm = 0.1,\n    report_to = \"wandb\", # Can use Weights & Biases\n    output_dir = hp_run_name + '_out',\n    run_name = hp_run_name\n)","metadata":{"id":"ptqkXK2D4d6p","outputId":"9d5551f4-0276-47ca-e4ca-e96c846cc976","trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:40:31.309974Z","iopub.execute_input":"2025-03-08T07:40:31.310648Z","iopub.status.idle":"2025-03-08T07:40:31.347242Z","shell.execute_reply.started":"2025-03-08T07:40:31.310624Z","shell.execute_reply":"2025-03-08T07:40:31.346416Z"}},"outputs":[{"name":"stdout","text":"Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\nWe will change the batch size of 1 to the `num_generations` of 6\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\nos.environ[\"TORCH_LOGS\"] = \"+dynamic\"\n\ntrainer = GRPOTrainer(\n    model = model,\n    processing_class = tokenizer,\n    reward_funcs = [\n        xmlcount_reward_func,\n        soft_format_reward_func,\n        strict_format_reward_func,\n        int_reward_func,\n        correctness_reward_func,\n        write_model_outputs_to_file\n    ],\n    args = training_args,\n    train_dataset = dataset,\n)\ntrainer.train()","metadata":{"id":"vzOuSVCL_GA9","outputId":"a71824d4-afd8-47ac-f0ea-eae276927e19","trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-03-08T07:40:31.348167Z","iopub.execute_input":"2025-03-08T07:40:31.348485Z","iopub.status.idle":"2025-03-08T15:07:57.178602Z","shell.execute_reply.started":"2025-03-08T07:40:31.348454Z","shell.execute_reply":"2025-03-08T15:07:57.177733Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 200\nO^O/ \\_/ \\    Batch size per device = 12 | Gradient accumulation steps = 1\n\\        /    Data Parallel GPUs = 1 | Total batch size (12 x 1 x 1) = 12\n \"-____-\"     Trainable parameters = 65,536,000/7,909,299,200 (0.83% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250308_074034-d7unxnjc</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/team-nik/dsc_250_train/runs/d7unxnjc' target=\"_blank\">Phi-4-gsm-200-steps</a></strong> to <a href='https://wandb.ai/team-nik/dsc_250_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/team-nik/dsc_250_train' target=\"_blank\">https://wandb.ai/team-nik/dsc_250_train</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/team-nik/dsc_250_train/runs/d7unxnjc' target=\"_blank\">https://wandb.ai/team-nik/dsc_250_train/runs/d7unxnjc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 7:25:05, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>reward</th>\n      <th>reward_std</th>\n      <th>completion_length</th>\n      <th>kl</th>\n      <th>rewards / xmlcount_reward_func</th>\n      <th>rewards / soft_format_reward_func</th>\n      <th>rewards / strict_format_reward_func</th>\n      <th>rewards / int_reward_func</th>\n      <th>rewards / correctness_reward_func</th>\n      <th>rewards / write_model_outputs_to_file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>-0.030583</td>\n      <td>0.074914</td>\n      <td>100.250000</td>\n      <td>0.000000</td>\n      <td>-0.030583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>118.916672</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000000</td>\n      <td>0.049917</td>\n      <td>0.078899</td>\n      <td>65.000000</td>\n      <td>0.000014</td>\n      <td>0.049917</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000000</td>\n      <td>0.020833</td>\n      <td>0.032275</td>\n      <td>120.000000</td>\n      <td>0.000006</td>\n      <td>0.020833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.000000</td>\n      <td>0.031250</td>\n      <td>0.034233</td>\n      <td>121.833336</td>\n      <td>0.000008</td>\n      <td>0.031250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.000000</td>\n      <td>-0.069417</td>\n      <td>0.136560</td>\n      <td>116.583336</td>\n      <td>0.000009</td>\n      <td>-0.069417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>97.333336</td>\n      <td>0.000017</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>81.500000</td>\n      <td>0.000013</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>94.500000</td>\n      <td>0.000010</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000000</td>\n      <td>0.010417</td>\n      <td>0.025516</td>\n      <td>94.000000</td>\n      <td>0.000130</td>\n      <td>0.010417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.000000</td>\n      <td>0.032833</td>\n      <td>0.080425</td>\n      <td>92.916672</td>\n      <td>0.000009</td>\n      <td>-0.008833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.000000</td>\n      <td>0.010417</td>\n      <td>0.025516</td>\n      <td>119.333336</td>\n      <td>0.000009</td>\n      <td>0.010417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.000000</td>\n      <td>-0.034083</td>\n      <td>0.083487</td>\n      <td>103.000000</td>\n      <td>0.000021</td>\n      <td>-0.034083</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>80.166672</td>\n      <td>0.000010</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.000000</td>\n      <td>-0.021083</td>\n      <td>0.085977</td>\n      <td>81.750000</td>\n      <td>0.000015</td>\n      <td>-0.021083</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.000000</td>\n      <td>-0.041833</td>\n      <td>0.185776</td>\n      <td>96.583336</td>\n      <td>0.000116</td>\n      <td>-0.041833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>95.666672</td>\n      <td>0.000016</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.000000</td>\n      <td>0.010417</td>\n      <td>0.025516</td>\n      <td>124.833336</td>\n      <td>0.000013</td>\n      <td>0.010417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.000000</td>\n      <td>-0.035417</td>\n      <td>0.164005</td>\n      <td>92.750000</td>\n      <td>0.000032</td>\n      <td>-0.035417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.000000</td>\n      <td>0.044250</td>\n      <td>0.081691</td>\n      <td>89.500000</td>\n      <td>0.000031</td>\n      <td>0.044250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>100.333336</td>\n      <td>0.000038</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.000000</td>\n      <td>0.010417</td>\n      <td>0.025516</td>\n      <td>97.583336</td>\n      <td>0.000045</td>\n      <td>0.010417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.000000</td>\n      <td>-0.055000</td>\n      <td>0.090452</td>\n      <td>68.666672</td>\n      <td>0.000065</td>\n      <td>-0.055000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>76.250000</td>\n      <td>0.000118</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>92.333336</td>\n      <td>0.000120</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.000000</td>\n      <td>-0.068583</td>\n      <td>0.167994</td>\n      <td>102.833336</td>\n      <td>0.000063</td>\n      <td>-0.068583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.000000</td>\n      <td>-0.011833</td>\n      <td>0.064635</td>\n      <td>99.833336</td>\n      <td>0.000175</td>\n      <td>-0.011833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>106.500000</td>\n      <td>0.000570</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.000000</td>\n      <td>0.010417</td>\n      <td>0.025516</td>\n      <td>95.000000</td>\n      <td>0.000122</td>\n      <td>0.010417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.000000</td>\n      <td>-0.026417</td>\n      <td>0.187019</td>\n      <td>133.750000</td>\n      <td>0.000131</td>\n      <td>-0.026417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.000000</td>\n      <td>-0.042667</td>\n      <td>0.137423</td>\n      <td>137.916672</td>\n      <td>0.000052</td>\n      <td>-0.042667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.000000</td>\n      <td>0.047583</td>\n      <td>0.110955</td>\n      <td>143.250000</td>\n      <td>0.000091</td>\n      <td>0.047583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.000000</td>\n      <td>-0.045250</td>\n      <td>0.110839</td>\n      <td>96.250000</td>\n      <td>0.000083</td>\n      <td>-0.045250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.000000</td>\n      <td>0.010417</td>\n      <td>0.025516</td>\n      <td>99.166672</td>\n      <td>0.000153</td>\n      <td>0.010417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.000000</td>\n      <td>0.010417</td>\n      <td>0.025516</td>\n      <td>79.166672</td>\n      <td>0.001060</td>\n      <td>0.010417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.000000</td>\n      <td>0.002167</td>\n      <td>0.045724</td>\n      <td>92.916672</td>\n      <td>0.000615</td>\n      <td>0.002167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>98.750000</td>\n      <td>0.000391</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.000000</td>\n      <td>-0.049083</td>\n      <td>0.153588</td>\n      <td>107.916672</td>\n      <td>0.000216</td>\n      <td>-0.049083</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>88.750000</td>\n      <td>0.000224</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.000000</td>\n      <td>0.010417</td>\n      <td>0.025516</td>\n      <td>101.666672</td>\n      <td>0.000162</td>\n      <td>0.010417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.000000</td>\n      <td>-0.006833</td>\n      <td>0.102854</td>\n      <td>94.666672</td>\n      <td>0.000312</td>\n      <td>-0.006833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.000000</td>\n      <td>-0.038750</td>\n      <td>0.145949</td>\n      <td>90.250000</td>\n      <td>0.000487</td>\n      <td>-0.038750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.000000</td>\n      <td>0.031250</td>\n      <td>0.057790</td>\n      <td>149.666672</td>\n      <td>0.000364</td>\n      <td>0.031250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.000000</td>\n      <td>0.031250</td>\n      <td>0.057790</td>\n      <td>116.666672</td>\n      <td>0.000216</td>\n      <td>0.031250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.000000</td>\n      <td>0.010417</td>\n      <td>0.025516</td>\n      <td>101.333336</td>\n      <td>0.000246</td>\n      <td>0.010417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.000000</td>\n      <td>0.027250</td>\n      <td>0.066749</td>\n      <td>91.416672</td>\n      <td>0.000215</td>\n      <td>0.027250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.000000</td>\n      <td>0.010417</td>\n      <td>0.025516</td>\n      <td>119.000000</td>\n      <td>0.000346</td>\n      <td>0.010417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>129.916672</td>\n      <td>0.000561</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.000000</td>\n      <td>0.020833</td>\n      <td>0.032275</td>\n      <td>112.166672</td>\n      <td>0.000620</td>\n      <td>0.020833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.000000</td>\n      <td>-0.032667</td>\n      <td>0.131048</td>\n      <td>110.750000</td>\n      <td>0.000280</td>\n      <td>-0.032667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.000000</td>\n      <td>0.032500</td>\n      <td>0.055000</td>\n      <td>98.250000</td>\n      <td>0.000463</td>\n      <td>0.032500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.000000</td>\n      <td>-0.009167</td>\n      <td>0.022454</td>\n      <td>99.833336</td>\n      <td>0.000331</td>\n      <td>-0.009167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>0.000000</td>\n      <td>0.039583</td>\n      <td>0.073387</td>\n      <td>104.583336</td>\n      <td>0.000615</td>\n      <td>0.039583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.000000</td>\n      <td>0.023417</td>\n      <td>0.050545</td>\n      <td>110.000000</td>\n      <td>0.000596</td>\n      <td>0.023417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.000000</td>\n      <td>0.145667</td>\n      <td>0.625565</td>\n      <td>139.833344</td>\n      <td>0.000380</td>\n      <td>-0.062667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.000000</td>\n      <td>0.017083</td>\n      <td>0.054311</td>\n      <td>105.083336</td>\n      <td>0.000477</td>\n      <td>0.017083</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>0.000000</td>\n      <td>0.010417</td>\n      <td>0.025516</td>\n      <td>97.166672</td>\n      <td>0.000486</td>\n      <td>0.010417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.000100</td>\n      <td>0.066250</td>\n      <td>0.076791</td>\n      <td>115.916672</td>\n      <td>0.001434</td>\n      <td>0.066250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>0.000000</td>\n      <td>0.007917</td>\n      <td>0.027405</td>\n      <td>87.500000</td>\n      <td>0.000468</td>\n      <td>0.007917</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.000100</td>\n      <td>0.198333</td>\n      <td>0.485815</td>\n      <td>104.583336</td>\n      <td>0.002593</td>\n      <td>-0.010000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>75.916672</td>\n      <td>0.001140</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.000000</td>\n      <td>-0.046333</td>\n      <td>0.164524</td>\n      <td>169.083344</td>\n      <td>0.000637</td>\n      <td>-0.046333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>0.000000</td>\n      <td>-0.049833</td>\n      <td>0.173097</td>\n      <td>135.833344</td>\n      <td>0.001133</td>\n      <td>-0.049833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>0.000100</td>\n      <td>0.011583</td>\n      <td>0.159000</td>\n      <td>151.333344</td>\n      <td>0.001784</td>\n      <td>0.011583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>91.500000</td>\n      <td>0.001128</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.000100</td>\n      <td>0.031250</td>\n      <td>0.034233</td>\n      <td>98.666672</td>\n      <td>0.001777</td>\n      <td>0.031250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>0.001600</td>\n      <td>0.020833</td>\n      <td>0.051031</td>\n      <td>103.083336</td>\n      <td>0.038831</td>\n      <td>0.020833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.000100</td>\n      <td>-0.004917</td>\n      <td>0.012043</td>\n      <td>115.083336</td>\n      <td>0.002059</td>\n      <td>-0.004917</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.000100</td>\n      <td>0.003167</td>\n      <td>0.067410</td>\n      <td>140.000000</td>\n      <td>0.001651</td>\n      <td>0.003167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.000200</td>\n      <td>0.223000</td>\n      <td>0.535299</td>\n      <td>94.916672</td>\n      <td>0.003831</td>\n      <td>0.014667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.000100</td>\n      <td>-0.024417</td>\n      <td>0.115610</td>\n      <td>146.166672</td>\n      <td>0.001995</td>\n      <td>-0.024417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.000200</td>\n      <td>-0.030583</td>\n      <td>0.158219</td>\n      <td>127.583336</td>\n      <td>0.004887</td>\n      <td>-0.030583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.000100</td>\n      <td>0.060083</td>\n      <td>0.093252</td>\n      <td>106.916672</td>\n      <td>0.002798</td>\n      <td>0.060083</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.000100</td>\n      <td>0.041667</td>\n      <td>0.059748</td>\n      <td>141.750000</td>\n      <td>0.002456</td>\n      <td>0.041667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.000100</td>\n      <td>0.020833</td>\n      <td>0.051031</td>\n      <td>122.166672</td>\n      <td>0.002433</td>\n      <td>0.020833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.000100</td>\n      <td>0.006500</td>\n      <td>0.103647</td>\n      <td>133.583344</td>\n      <td>0.003612</td>\n      <td>0.006500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.000200</td>\n      <td>0.041333</td>\n      <td>0.101246</td>\n      <td>109.500000</td>\n      <td>0.005857</td>\n      <td>0.041333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.000300</td>\n      <td>-0.008417</td>\n      <td>0.148144</td>\n      <td>107.916672</td>\n      <td>0.006377</td>\n      <td>-0.008417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.000200</td>\n      <td>0.072917</td>\n      <td>0.057790</td>\n      <td>168.833344</td>\n      <td>0.003927</td>\n      <td>0.072917</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.000100</td>\n      <td>0.041667</td>\n      <td>0.064550</td>\n      <td>124.166672</td>\n      <td>0.003041</td>\n      <td>0.041667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.000300</td>\n      <td>0.018167</td>\n      <td>0.044499</td>\n      <td>96.750000</td>\n      <td>0.007287</td>\n      <td>0.018167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.000200</td>\n      <td>0.052083</td>\n      <td>0.057790</td>\n      <td>128.416672</td>\n      <td>0.003945</td>\n      <td>0.052083</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.000500</td>\n      <td>-0.026917</td>\n      <td>0.150116</td>\n      <td>117.250000</td>\n      <td>0.012659</td>\n      <td>-0.026917</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.000200</td>\n      <td>0.052083</td>\n      <td>0.057790</td>\n      <td>153.333344</td>\n      <td>0.005114</td>\n      <td>0.052083</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.000800</td>\n      <td>0.011833</td>\n      <td>0.062421</td>\n      <td>129.916672</td>\n      <td>0.018792</td>\n      <td>0.011833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.000200</td>\n      <td>0.083333</td>\n      <td>0.032275</td>\n      <td>190.583344</td>\n      <td>0.003846</td>\n      <td>0.083333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.000100</td>\n      <td>0.006333</td>\n      <td>0.133759</td>\n      <td>144.500000</td>\n      <td>0.003719</td>\n      <td>0.006333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.001600</td>\n      <td>0.262167</td>\n      <td>0.495224</td>\n      <td>147.000000</td>\n      <td>0.040023</td>\n      <td>0.053833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.000500</td>\n      <td>0.062500</td>\n      <td>0.068465</td>\n      <td>140.833344</td>\n      <td>0.012568</td>\n      <td>0.062500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.000200</td>\n      <td>0.031250</td>\n      <td>0.057790</td>\n      <td>131.833344</td>\n      <td>0.005197</td>\n      <td>0.031250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.000300</td>\n      <td>0.006250</td>\n      <td>0.211585</td>\n      <td>188.500000</td>\n      <td>0.006554</td>\n      <td>0.006250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.000400</td>\n      <td>0.008250</td>\n      <td>0.165951</td>\n      <td>108.833336</td>\n      <td>0.011250</td>\n      <td>0.008250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.000500</td>\n      <td>0.083333</td>\n      <td>0.032275</td>\n      <td>176.750000</td>\n      <td>0.012959</td>\n      <td>0.083333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.000200</td>\n      <td>0.076500</td>\n      <td>0.034293</td>\n      <td>155.000000</td>\n      <td>0.005908</td>\n      <td>0.076500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.000700</td>\n      <td>0.040500</td>\n      <td>0.080334</td>\n      <td>173.666672</td>\n      <td>0.016420</td>\n      <td>0.040500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.000900</td>\n      <td>0.236833</td>\n      <td>0.532959</td>\n      <td>152.000000</td>\n      <td>0.021747</td>\n      <td>0.028500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.000200</td>\n      <td>0.096333</td>\n      <td>0.046831</td>\n      <td>197.666672</td>\n      <td>0.005502</td>\n      <td>0.096333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.000300</td>\n      <td>0.106417</td>\n      <td>0.103619</td>\n      <td>157.000000</td>\n      <td>0.006493</td>\n      <td>0.106417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.000500</td>\n      <td>0.072917</td>\n      <td>0.057790</td>\n      <td>150.750000</td>\n      <td>0.012054</td>\n      <td>0.072917</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.000300</td>\n      <td>0.041667</td>\n      <td>0.059748</td>\n      <td>157.000000</td>\n      <td>0.008322</td>\n      <td>0.041667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>101</td>\n      <td>0.000400</td>\n      <td>0.083333</td>\n      <td>0.059748</td>\n      <td>195.500000</td>\n      <td>0.011109</td>\n      <td>0.083333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>102</td>\n      <td>0.000600</td>\n      <td>0.093750</td>\n      <td>0.057790</td>\n      <td>184.750000</td>\n      <td>0.015215</td>\n      <td>0.093750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>103</td>\n      <td>0.000400</td>\n      <td>0.028667</td>\n      <td>0.099554</td>\n      <td>153.000000</td>\n      <td>0.010282</td>\n      <td>0.028667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>104</td>\n      <td>0.000500</td>\n      <td>0.093750</td>\n      <td>0.057790</td>\n      <td>195.500000</td>\n      <td>0.013264</td>\n      <td>0.093750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>0.000200</td>\n      <td>0.097000</td>\n      <td>0.083247</td>\n      <td>165.333344</td>\n      <td>0.005732</td>\n      <td>0.097000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>106</td>\n      <td>0.000400</td>\n      <td>0.083333</td>\n      <td>0.059748</td>\n      <td>172.833344</td>\n      <td>0.010448</td>\n      <td>0.083333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>107</td>\n      <td>0.000900</td>\n      <td>-0.044167</td>\n      <td>0.235096</td>\n      <td>187.500000</td>\n      <td>0.021457</td>\n      <td>-0.044167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>108</td>\n      <td>0.000500</td>\n      <td>0.072917</td>\n      <td>0.066508</td>\n      <td>193.083344</td>\n      <td>0.012243</td>\n      <td>0.072917</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>109</td>\n      <td>0.000600</td>\n      <td>0.072917</td>\n      <td>0.066508</td>\n      <td>182.250000</td>\n      <td>0.015932</td>\n      <td>0.072917</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.000600</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>200.000000</td>\n      <td>0.015349</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>111</td>\n      <td>0.001100</td>\n      <td>0.062500</td>\n      <td>0.064550</td>\n      <td>167.416672</td>\n      <td>0.026603</td>\n      <td>0.062500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>112</td>\n      <td>0.000500</td>\n      <td>0.114583</td>\n      <td>0.065044</td>\n      <td>192.000000</td>\n      <td>0.012799</td>\n      <td>0.114583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>113</td>\n      <td>0.000600</td>\n      <td>0.083333</td>\n      <td>0.064550</td>\n      <td>184.916672</td>\n      <td>0.015297</td>\n      <td>0.083333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>114</td>\n      <td>0.000700</td>\n      <td>0.038917</td>\n      <td>0.122880</td>\n      <td>176.583344</td>\n      <td>0.018405</td>\n      <td>0.038917</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>0.000900</td>\n      <td>0.083333</td>\n      <td>0.064550</td>\n      <td>175.416672</td>\n      <td>0.022298</td>\n      <td>0.083333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>116</td>\n      <td>0.000500</td>\n      <td>0.079083</td>\n      <td>0.112472</td>\n      <td>197.500000</td>\n      <td>0.013506</td>\n      <td>0.079083</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>117</td>\n      <td>0.000500</td>\n      <td>0.041667</td>\n      <td>0.059748</td>\n      <td>177.250000</td>\n      <td>0.013429</td>\n      <td>0.041667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>118</td>\n      <td>0.005500</td>\n      <td>0.049750</td>\n      <td>0.099137</td>\n      <td>178.250000</td>\n      <td>0.137288</td>\n      <td>0.049750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>119</td>\n      <td>0.000500</td>\n      <td>0.402500</td>\n      <td>0.675249</td>\n      <td>173.833344</td>\n      <td>0.013388</td>\n      <td>-0.014167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.083333</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.000700</td>\n      <td>0.218333</td>\n      <td>0.569207</td>\n      <td>176.000000</td>\n      <td>0.018595</td>\n      <td>0.010000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>121</td>\n      <td>0.000600</td>\n      <td>0.302583</td>\n      <td>0.487713</td>\n      <td>190.000000</td>\n      <td>0.015687</td>\n      <td>0.094250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>122</td>\n      <td>0.000600</td>\n      <td>0.038167</td>\n      <td>0.212697</td>\n      <td>198.000000</td>\n      <td>0.015067</td>\n      <td>0.038167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>123</td>\n      <td>0.003100</td>\n      <td>0.104167</td>\n      <td>0.051031</td>\n      <td>200.000000</td>\n      <td>0.076876</td>\n      <td>0.104167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>124</td>\n      <td>0.000800</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>200.000000</td>\n      <td>0.018831</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.000900</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>200.000000</td>\n      <td>0.022613</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>126</td>\n      <td>0.000900</td>\n      <td>0.127500</td>\n      <td>0.092605</td>\n      <td>158.833344</td>\n      <td>0.021652</td>\n      <td>0.127500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>127</td>\n      <td>0.001800</td>\n      <td>0.061333</td>\n      <td>0.137195</td>\n      <td>171.166672</td>\n      <td>0.045484</td>\n      <td>0.061333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>128</td>\n      <td>0.000600</td>\n      <td>0.127667</td>\n      <td>0.089838</td>\n      <td>175.166672</td>\n      <td>0.016098</td>\n      <td>0.127667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>129</td>\n      <td>0.001200</td>\n      <td>0.287000</td>\n      <td>0.385918</td>\n      <td>199.000000</td>\n      <td>0.030127</td>\n      <td>-0.004667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.125000</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.001100</td>\n      <td>0.288167</td>\n      <td>0.482010</td>\n      <td>192.500000</td>\n      <td>0.028689</td>\n      <td>0.079833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>131</td>\n      <td>0.001200</td>\n      <td>0.104167</td>\n      <td>0.032275</td>\n      <td>179.166672</td>\n      <td>0.029462</td>\n      <td>0.104167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>132</td>\n      <td>0.000600</td>\n      <td>0.114583</td>\n      <td>0.025516</td>\n      <td>197.750000</td>\n      <td>0.015076</td>\n      <td>0.114583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>133</td>\n      <td>0.001900</td>\n      <td>0.104167</td>\n      <td>0.032275</td>\n      <td>186.916672</td>\n      <td>0.047803</td>\n      <td>0.104167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>134</td>\n      <td>0.000700</td>\n      <td>0.218917</td>\n      <td>0.578632</td>\n      <td>192.666672</td>\n      <td>0.016903</td>\n      <td>0.010583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>0.001300</td>\n      <td>0.091333</td>\n      <td>0.067439</td>\n      <td>190.916672</td>\n      <td>0.032088</td>\n      <td>0.091333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>136</td>\n      <td>0.001300</td>\n      <td>0.128750</td>\n      <td>0.076791</td>\n      <td>170.416672</td>\n      <td>0.032760</td>\n      <td>0.128750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>137</td>\n      <td>0.000500</td>\n      <td>0.104167</td>\n      <td>0.051031</td>\n      <td>200.000000</td>\n      <td>0.012829</td>\n      <td>0.104167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>138</td>\n      <td>0.001000</td>\n      <td>0.122667</td>\n      <td>0.081792</td>\n      <td>186.500000</td>\n      <td>0.024283</td>\n      <td>0.122667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>139</td>\n      <td>0.000900</td>\n      <td>0.093750</td>\n      <td>0.034233</td>\n      <td>186.416672</td>\n      <td>0.023330</td>\n      <td>0.093750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.000600</td>\n      <td>0.116250</td>\n      <td>0.021433</td>\n      <td>193.750000</td>\n      <td>0.016144</td>\n      <td>0.116250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>141</td>\n      <td>0.000800</td>\n      <td>0.059250</td>\n      <td>0.133373</td>\n      <td>185.500000</td>\n      <td>0.019578</td>\n      <td>0.059250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>142</td>\n      <td>0.000600</td>\n      <td>-0.030583</td>\n      <td>0.183698</td>\n      <td>194.916672</td>\n      <td>0.014222</td>\n      <td>-0.030583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>143</td>\n      <td>0.000800</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>200.000000</td>\n      <td>0.021110</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>144</td>\n      <td>0.000900</td>\n      <td>0.114583</td>\n      <td>0.025516</td>\n      <td>200.000000</td>\n      <td>0.022741</td>\n      <td>0.114583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>145</td>\n      <td>0.000600</td>\n      <td>0.114583</td>\n      <td>0.025516</td>\n      <td>200.000000</td>\n      <td>0.015008</td>\n      <td>0.114583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>146</td>\n      <td>0.000900</td>\n      <td>0.050417</td>\n      <td>0.138863</td>\n      <td>187.166672</td>\n      <td>0.022939</td>\n      <td>0.050417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>147</td>\n      <td>0.001000</td>\n      <td>0.070667</td>\n      <td>0.108224</td>\n      <td>177.916672</td>\n      <td>0.024506</td>\n      <td>0.070667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>148</td>\n      <td>0.008100</td>\n      <td>-0.057333</td>\n      <td>0.224320</td>\n      <td>169.833344</td>\n      <td>0.201504</td>\n      <td>-0.057333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>149</td>\n      <td>0.000700</td>\n      <td>0.069333</td>\n      <td>0.109542</td>\n      <td>191.583344</td>\n      <td>0.016652</td>\n      <td>0.069333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.000500</td>\n      <td>0.104167</td>\n      <td>0.051031</td>\n      <td>190.166672</td>\n      <td>0.011581</td>\n      <td>0.104167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>151</td>\n      <td>0.000900</td>\n      <td>0.041000</td>\n      <td>0.080850</td>\n      <td>179.750000</td>\n      <td>0.021784</td>\n      <td>0.041000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>152</td>\n      <td>0.004400</td>\n      <td>0.067167</td>\n      <td>0.114622</td>\n      <td>183.833344</td>\n      <td>0.109320</td>\n      <td>0.067167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>153</td>\n      <td>0.000700</td>\n      <td>0.086500</td>\n      <td>0.088723</td>\n      <td>198.250000</td>\n      <td>0.018105</td>\n      <td>0.086500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>154</td>\n      <td>0.000900</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>200.000000</td>\n      <td>0.021478</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>155</td>\n      <td>0.000800</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>200.000000</td>\n      <td>0.020827</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>156</td>\n      <td>0.000800</td>\n      <td>0.443333</td>\n      <td>0.544667</td>\n      <td>198.916672</td>\n      <td>0.018869</td>\n      <td>0.026667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.083333</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>157</td>\n      <td>0.001000</td>\n      <td>0.296833</td>\n      <td>0.485256</td>\n      <td>199.583344</td>\n      <td>0.025374</td>\n      <td>0.088500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>158</td>\n      <td>0.001300</td>\n      <td>0.114583</td>\n      <td>0.025516</td>\n      <td>200.000000</td>\n      <td>0.033407</td>\n      <td>0.114583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>159</td>\n      <td>0.000800</td>\n      <td>0.043167</td>\n      <td>0.231360</td>\n      <td>176.083344</td>\n      <td>0.019252</td>\n      <td>0.043167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.000800</td>\n      <td>0.214167</td>\n      <td>0.582359</td>\n      <td>198.916672</td>\n      <td>0.020980</td>\n      <td>0.005833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>161</td>\n      <td>0.000800</td>\n      <td>0.097417</td>\n      <td>0.067565</td>\n      <td>197.833344</td>\n      <td>0.019693</td>\n      <td>0.097417</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>162</td>\n      <td>0.000500</td>\n      <td>0.254333</td>\n      <td>0.463017</td>\n      <td>200.000000</td>\n      <td>0.013472</td>\n      <td>0.046000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>163</td>\n      <td>0.000400</td>\n      <td>0.186583</td>\n      <td>0.536023</td>\n      <td>186.250000</td>\n      <td>0.010063</td>\n      <td>-0.021750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>164</td>\n      <td>0.001200</td>\n      <td>0.093750</td>\n      <td>0.057790</td>\n      <td>179.833344</td>\n      <td>0.028931</td>\n      <td>0.093750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>0.000900</td>\n      <td>0.010333</td>\n      <td>0.132210</td>\n      <td>169.916672</td>\n      <td>0.023653</td>\n      <td>0.010333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>166</td>\n      <td>0.000900</td>\n      <td>0.124750</td>\n      <td>0.064749</td>\n      <td>188.166672</td>\n      <td>0.022077</td>\n      <td>0.124750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>167</td>\n      <td>0.001000</td>\n      <td>0.083333</td>\n      <td>0.064550</td>\n      <td>188.416672</td>\n      <td>0.025484</td>\n      <td>0.083333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>168</td>\n      <td>0.001100</td>\n      <td>0.038667</td>\n      <td>0.111023</td>\n      <td>196.416672</td>\n      <td>0.027271</td>\n      <td>0.038667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>169</td>\n      <td>0.000700</td>\n      <td>0.114583</td>\n      <td>0.025516</td>\n      <td>187.583344</td>\n      <td>0.018293</td>\n      <td>0.114583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.001400</td>\n      <td>0.024917</td>\n      <td>0.174467</td>\n      <td>194.500000</td>\n      <td>0.035890</td>\n      <td>0.024917</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>171</td>\n      <td>0.000800</td>\n      <td>0.054500</td>\n      <td>0.205057</td>\n      <td>200.000000</td>\n      <td>0.019597</td>\n      <td>0.054500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>172</td>\n      <td>0.001300</td>\n      <td>0.026000</td>\n      <td>0.187498</td>\n      <td>198.250000</td>\n      <td>0.032742</td>\n      <td>0.026000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>173</td>\n      <td>0.000600</td>\n      <td>0.104167</td>\n      <td>0.032275</td>\n      <td>200.000000</td>\n      <td>0.014997</td>\n      <td>0.104167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>174</td>\n      <td>0.000700</td>\n      <td>0.018000</td>\n      <td>0.098260</td>\n      <td>187.166672</td>\n      <td>0.016668</td>\n      <td>0.018000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.000700</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>200.000000</td>\n      <td>0.017790</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>176</td>\n      <td>0.001100</td>\n      <td>0.068833</td>\n      <td>0.159183</td>\n      <td>185.833344</td>\n      <td>0.026972</td>\n      <td>0.068833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>177</td>\n      <td>0.000700</td>\n      <td>0.036750</td>\n      <td>0.150838</td>\n      <td>199.333344</td>\n      <td>0.018576</td>\n      <td>0.036750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>178</td>\n      <td>0.000800</td>\n      <td>0.093750</td>\n      <td>0.057790</td>\n      <td>177.416672</td>\n      <td>0.020309</td>\n      <td>0.093750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>179</td>\n      <td>0.000500</td>\n      <td>0.212667</td>\n      <td>0.536644</td>\n      <td>170.750000</td>\n      <td>0.012948</td>\n      <td>0.004333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.000600</td>\n      <td>0.099167</td>\n      <td>0.102149</td>\n      <td>179.000000</td>\n      <td>0.014509</td>\n      <td>0.099167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>181</td>\n      <td>0.000600</td>\n      <td>0.101500</td>\n      <td>0.057563</td>\n      <td>198.166672</td>\n      <td>0.015283</td>\n      <td>0.101500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>182</td>\n      <td>0.001400</td>\n      <td>0.066750</td>\n      <td>0.100369</td>\n      <td>180.666672</td>\n      <td>0.035244</td>\n      <td>0.066750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>183</td>\n      <td>0.000500</td>\n      <td>0.052250</td>\n      <td>0.109539</td>\n      <td>198.750000</td>\n      <td>0.012444</td>\n      <td>0.052250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>184</td>\n      <td>0.001000</td>\n      <td>0.104167</td>\n      <td>0.032275</td>\n      <td>185.666672</td>\n      <td>0.025266</td>\n      <td>0.104167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>0.000900</td>\n      <td>0.297500</td>\n      <td>0.455636</td>\n      <td>191.750000</td>\n      <td>0.022160</td>\n      <td>0.089167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>186</td>\n      <td>0.000700</td>\n      <td>0.443500</td>\n      <td>0.518417</td>\n      <td>200.000000</td>\n      <td>0.018175</td>\n      <td>0.026833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.083333</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>187</td>\n      <td>0.000700</td>\n      <td>0.069167</td>\n      <td>0.066976</td>\n      <td>185.750000</td>\n      <td>0.017364</td>\n      <td>0.069167</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>188</td>\n      <td>0.001400</td>\n      <td>0.057667</td>\n      <td>0.119229</td>\n      <td>162.083344</td>\n      <td>0.033977</td>\n      <td>0.057667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>189</td>\n      <td>0.004000</td>\n      <td>0.088500</td>\n      <td>0.067133</td>\n      <td>184.833344</td>\n      <td>0.099231</td>\n      <td>0.088500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.000700</td>\n      <td>0.111833</td>\n      <td>0.032252</td>\n      <td>200.000000</td>\n      <td>0.018316</td>\n      <td>0.111833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>191</td>\n      <td>0.001200</td>\n      <td>0.114583</td>\n      <td>0.057790</td>\n      <td>182.583344</td>\n      <td>0.030354</td>\n      <td>0.114583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>192</td>\n      <td>0.001200</td>\n      <td>0.114583</td>\n      <td>0.025516</td>\n      <td>200.000000</td>\n      <td>0.030752</td>\n      <td>0.114583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>193</td>\n      <td>0.029400</td>\n      <td>0.093750</td>\n      <td>0.057790</td>\n      <td>183.083344</td>\n      <td>0.734014</td>\n      <td>0.093750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>194</td>\n      <td>0.000700</td>\n      <td>0.076917</td>\n      <td>0.130204</td>\n      <td>192.083344</td>\n      <td>0.016432</td>\n      <td>0.076917</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>0.002300</td>\n      <td>0.264583</td>\n      <td>0.544466</td>\n      <td>175.833344</td>\n      <td>0.056724</td>\n      <td>0.056250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>196</td>\n      <td>0.000800</td>\n      <td>0.282000</td>\n      <td>0.490474</td>\n      <td>192.333344</td>\n      <td>0.020110</td>\n      <td>0.073667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.041667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>197</td>\n      <td>0.000900</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>200.000000</td>\n      <td>0.022766</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>198</td>\n      <td>0.000800</td>\n      <td>0.114583</td>\n      <td>0.025516</td>\n      <td>193.750000</td>\n      <td>0.018883</td>\n      <td>0.114583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>199</td>\n      <td>0.000500</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>200.000000</td>\n      <td>0.013346</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.000800</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>200.000000</td>\n      <td>0.021080</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=0.0007307642650229696, metrics={'train_runtime': 26843.0408, 'train_samples_per_second': 0.089, 'train_steps_per_second': 0.007, 'total_flos': 0.0, 'train_loss': 0.0007307642650229696})"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"# save the model! ","metadata":{}},{"cell_type":"code","source":"saving_name = 'LightFury9/' + hp_run_name\ntrainer.push_to_hub( saving_name , token='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')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T15:07:57.179634Z","iopub.execute_input":"2025-03-08T15:07:57.179855Z","iopub.status.idle":"2025-03-08T15:08:06.774819Z","shell.execute_reply.started":"2025-03-08T15:07:57.179835Z","shell.execute_reply":"2025-03-08T15:08:06.773779Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecebca033daf44c4b7cf0eb66383d48d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/262M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8e11a5d6c30483cb77104709ac16c13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"202f632648794a66a2c5d201c5929475"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/LightFury9/Phi-4-gsm-200-steps_out/commit/2235166e28bda0849dec0d2653732fd139de675b', commit_message='LightFury9/Phi-4-gsm-200-steps', commit_description='', oid='2235166e28bda0849dec0d2653732fd139de675b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/LightFury9/Phi-4-gsm-200-steps_out', endpoint='https://huggingface.co', repo_type='model', repo_id='LightFury9/Phi-4-gsm-200-steps_out'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"model.save_lora(\"grpo_saved_lora\")","metadata":{"id":"AL-BcuB1VLIv","trusted":true,"execution":{"iopub.status.busy":"2025-03-08T15:08:06.775992Z","iopub.execute_input":"2025-03-08T15:08:06.776406Z","iopub.status.idle":"2025-03-08T15:08:07.355466Z","shell.execute_reply.started":"2025-03-08T15:08:06.776363Z","shell.execute_reply":"2025-03-08T15:08:07.354798Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# \n# Just LoRA adapters\nif False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\nif False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"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\")\n\n\n\n# Merge to 16bit\n# if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n# if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n\n# # Merge to 4bit\n# if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n# if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")","metadata":{"id":"NjXGTkp7YNtB","trusted":true,"execution":{"iopub.status.busy":"2025-03-08T15:08:07.356322Z","iopub.execute_input":"2025-03-08T15:08:07.356609Z","iopub.status.idle":"2025-03-08T15:08:07.361889Z","shell.execute_reply.started":"2025-03-08T15:08:07.356581Z","shell.execute_reply":"2025-03-08T15:08:07.360927Z"}},"outputs":[],"execution_count":12}]}